{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_depth.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5AF8j7CxdXv"
      },
      "source": [
        "# from PIL.ExifTags import TAGS\n",
        "# from PIL import Image\n",
        "import os\n",
        "from PyQt5.QtWidgets import QApplication\n",
        "import sys\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def shape_to_np(shape, dtype=\"int\"):\n",
        "    # initialize the list of (x, y)-coordinates\n",
        "    coords = np.zeros((68, 2), dtype=dtype)\n",
        "    # loop over the 68 facial landmarks and convert them\n",
        "    # to a 2-tuple of (x, y)-coordinates\n",
        "    for i in range(0, 68):\n",
        "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "    # return the list of (x, y)-coordinates\n",
        "    return coords\n",
        "\n",
        "\n",
        "def eye_on_mask(mask, side):\n",
        "    points = [shape[i] for i in side]\n",
        "    points = np.array(points, dtype=np.int32)\n",
        "    mask = cv2.fillConvexPoly(mask, points, 255)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def contouring(thresh, mid, img, right=False):\n",
        "    cnts, _ = cv2.findContours(\n",
        "        thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    try:\n",
        "        cnt = max(cnts, key=cv2.contourArea)\n",
        "        M = cv2.moments(cnt)\n",
        "        cx = int(M['m10']/M['m00'])\n",
        "        cy = int(M['m01']/M['m00'])\n",
        "        if right:\n",
        "            cx += mid\n",
        "        cv2.circle(img, (cx, cy), 4, (0, 0, 255), 2)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\n",
        "    './detector/shape_predictor_68_face_landmarks.dat')  # remember to change the path\n",
        "\n",
        "left = [36, 37, 38, 39, 40, 41]\n",
        "right = [42, 43, 44, 45, 46, 47]\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "ret, img = cap.read()\n",
        "thresh = img.copy()\n",
        "\n",
        "cv2.namedWindow('image')\n",
        "kernel = np.ones((9, 9), np.uint8)\n",
        "\n",
        "\n",
        "def nothing(x):\n",
        "    pass\n",
        "\n",
        "\n",
        "cv2.createTrackbar('threshold', 'image', 0, 255, nothing)\n",
        "\n",
        "# calculate dpi of the device\n",
        "\n",
        "\n",
        "def calculateDPI():\n",
        "    app = QApplication(sys.argv)\n",
        "    screen = app.screens()[0]\n",
        "    dpi = screen.physicalDotsPerInch()\n",
        "    app.quit()\n",
        "    return dpi\n",
        "\n",
        "\n",
        "# focal length\n",
        "\n",
        "\n",
        "# def calculate_focal_len(img):\n",
        "#     image = sys.argv[1]\n",
        "#     # https://stackoverflow.com/questions/21697645/how-to-extract-metadata-from-a-image-using-python\n",
        "#     # refer the last ans, maybe it requires the name of the image\n",
        "#     for (tag, value) in Image.open(image)._getexif().iteritems():\n",
        "#         if TAGS.get(tag) == 'FocalLength':\n",
        "#             return value\n",
        "#         # print '%s = %s' % (TAGS.get(tag), value)\n",
        "\n",
        "#     img = Image.open(\"/path/to/file.jpg\")\n",
        "#     exif = {TAGS[k]: v for k,\n",
        "#             v in img._getexif().items() if k in TAGS}\n",
        "\n",
        "\n",
        "while(True):\n",
        "    ret, img = cap.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    rects = detector(gray, 1)\n",
        "    for rect in rects:\n",
        "\n",
        "        shape = predictor(gray, rect)\n",
        "        print(shape)\n",
        "        shape = shape_to_np(shape)\n",
        "        mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "        mask = eye_on_mask(mask, left)\n",
        "        mask = eye_on_mask(mask, right)\n",
        "        mask = cv2.dilate(mask, kernel, 5)\n",
        "        eyes = cv2.bitwise_and(img, img, mask=mask)\n",
        "        mask = (eyes == [0, 0, 0]).all(axis=2)\n",
        "        eyes[mask] = [255, 255, 255]\n",
        "        mid = (shape[42][0] + shape[39][0]) // 2\n",
        "        iris_diam_px = abs(shape[42][0] - shape[39][0])\n",
        "        dpi = calculateDPI()\n",
        "        iris_diam_mm = (iris_diam_px * 25.4) / dpi\n",
        "        focal_Length = 2000\n",
        "        iris_depth = (focal_Length*1.17)/iris_diam_px\n",
        "        print(f\"iris_diam_px: {iris_diam_px}, iris_diam_mm: {iris_diam_mm}\")\n",
        "        print(f\"iris_depth: {iris_depth}\")\n",
        "        eyes_gray = cv2.cvtColor(eyes, cv2.COLOR_BGR2GRAY)\n",
        "        threshold = cv2.getTrackbarPos('threshold', 'image')\n",
        "        _, thresh = cv2.threshold(eyes_gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "        thresh = cv2.erode(thresh, None, iterations=2)  # 1\n",
        "        thresh = cv2.dilate(thresh, None, iterations=4)  # 2\n",
        "        thresh = cv2.medianBlur(thresh, 3)  # 3\n",
        "        thresh = cv2.bitwise_not(thresh)\n",
        "        contouring(thresh[:, 0:mid], mid, img)\n",
        "        contouring(thresh[:, mid:], mid, img, True)\n",
        "        # for (x, y) in shape[36:48]:\n",
        "        #     cv2.circle(img, (x, y), 2, (255, 0, 0), -1)\n",
        "    # show the image with the face detections + facial landmarks\n",
        "    cv2.imshow('eyes', img)\n",
        "    cv2.imshow(\"image\", thresh)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}